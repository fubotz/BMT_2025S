{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Translation Automatic Metrics\n",
        "\n",
        "- BLEU\n",
        "- chrF\n",
        "- COMET\n",
        "\n"
      ],
      "metadata": {
        "id": "WD9YWbV0AaFt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZLn9O7DJAULH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ea95dca-c623-4b77-b9d8-d993c04dfdbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.11/dist-packages (2.5.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (3.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (1.26.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\n"
          ]
        }
      ],
      "source": [
        "# install the metrics\n",
        "# we only have to do it once per session\n",
        "# install BLEU and chrF\n",
        "!pip install sacrebleu #==2.5.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install COMET\n",
        "!pip install unbabel-comet #==2.2.6"
      ],
      "metadata": {
        "id": "M-q3SyRoBHjC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bcbfbda-f648-4ce3-92da-1f2c8cec4253"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: unbabel-comet in /usr/local/lib/python3.11/dist-packages (2.2.6)\n",
            "Requirement already satisfied: entmax<2.0,>=1.1 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (1.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (0.33.0)\n",
            "Requirement already satisfied: jsonargparse==3.13.1 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (3.13.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (2.2.2)\n",
            "Requirement already satisfied: protobuf<5.0.0,>=4.24.4 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (4.25.8)\n",
            "Requirement already satisfied: pytorch-lightning<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (2.5.2)\n",
            "Requirement already satisfied: sacrebleu<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (2.5.1)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.5.4 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (1.15.3)\n",
            "Requirement already satisfied: sentencepiece<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchmetrics<0.11.0,>=0.10.2 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (0.10.3)\n",
            "Requirement already satisfied: transformers<5.0,>=4.17 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (4.52.4)\n",
            "Requirement already satisfied: PyYAML>=3.13 in /usr/local/lib/python3.11/dist-packages (from jsonargparse==3.13.1->unbabel-comet) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.1->unbabel-comet) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.1->unbabel-comet) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.1->unbabel-comet) (2025.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (0.14.3)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (3.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (5.4.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.6.0->unbabel-comet) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0,>=4.17->unbabel-comet) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0,>=4.17->unbabel-comet) (0.5.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (3.11.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (75.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.1->unbabel-comet) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.6.0->unbabel-comet) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2025.6.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.20.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload Text Files\n",
        "\n",
        "We need to upload the text files with the Source, Reference translation, and MT systems (engines) output.\n",
        "\n",
        "You upload files in the **directory** icon.\n",
        "\n",
        "--> Alternative: clone repo"
      ],
      "metadata": {
        "id": "lvGk5K-wCfQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#clone repo from Github and navigate to correct working directory\n",
        "!git clone https://github.com/fubotz/BMT_2025S\n",
        "%cd /content/BMT_2025S/week11_files"
      ],
      "metadata": {
        "id": "vjgielbpPIMQ",
        "outputId": "db148705-070f-4dc7-c723-9b7ddb37d705",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'BMT_2025S'...\n",
            "remote: Enumerating objects: 567, done.\u001b[K\n",
            "remote: Counting objects: 100% (199/199), done.\u001b[K\n",
            "remote: Compressing objects: 100% (190/190), done.\u001b[K\n",
            "remote: Total 567 (delta 128), reused 8 (delta 8), pack-reused 368 (from 1)\u001b[K\n",
            "Receiving objects: 100% (567/567), 172.54 MiB | 28.52 MiB/s, done.\n",
            "Resolving deltas: 100% (303/303), done.\n",
            "Updating files: 100% (78/78), done.\n",
            "/content/BMT_2025S/week11_files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute BLEU and chrF Scores\n",
        "\n",
        "This is the command to compute BLEU and chrF:\n",
        "\n",
        "sacrebleu reference-file -l language pair -i MT output -m metrics\n",
        "\n",
        "!sacrebleu en-de.vaccine.reference.de -l en-de -i en-de.opuscat.original.de -m bleu chrf\n",
        "\n",
        "#IMPORTANT:\n",
        "\n",
        "Using --paired-bs tells sacrebleu to evaluate both system1 AND system2 on the same set of references and to perform statistical significance testing using paired bootstrap resampling. This method is used to determine whether the difference in BLEU/chrF between the two systems is statistically significant, not just due to chance."
      ],
      "metadata": {
        "id": "ANKFYtADCOxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sacrebleu Vienna_Environmental.en-de.test.de -l en-de -i Vienna_Environmental.en-de.test.marian.de Vienna_Environmental.en-de.test.nllb.de -m bleu chrf --paired-bs\n",
        "#gold standard translation - sytem1 - system2"
      ],
      "metadata": {
        "id": "EB2xGXQmCI3k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fbaf787-9a2d-405a-89d6-dd4bb43ba1a1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sacreBLEU: Found 2 systems.\n",
            "sacreBLEU: Pre-computing BLEU statistics for 'Baseline: Vienna_Environmental.en-de.test.marian.de'\n",
            "sacreBLEU: Pre-computing CHRF statistics for 'Baseline: Vienna_Environmental.en-de.test.marian.de'\n",
            "sacreBLEU: Computing BLEU for 'Vienna_Environmental.en-de.test.nllb.de' and extracting sufficient statistics\n",
            "sacreBLEU:  > Performing paired bootstrap resampling test (# resamples: 1000)\n",
            "sacreBLEU: Computing chrF2 for 'Vienna_Environmental.en-de.test.nllb.de' and extracting sufficient statistics\n",
            "sacreBLEU:  > Performing paired bootstrap resampling test (# resamples: 1000)\n",
            "[\n",
            "    {\n",
            "        \"system\": \"Baseline: Vienna_Environmental.en-de.test.marian.de\",\n",
            "        \"BLEU\": {\n",
            "            \"score\": 18.767901172132877,\n",
            "            \"p_value\": null,\n",
            "            \"mean\": 19.002123586430987,\n",
            "            \"ci\": 4.49199024497201\n",
            "        },\n",
            "        \"chrF2\": {\n",
            "            \"score\": 57.09016511907269,\n",
            "            \"p_value\": null,\n",
            "            \"mean\": 57.11701761337507,\n",
            "            \"ci\": 2.824043711111031\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"system\": \"Vienna_Environmental.en-de.test.nllb.de\",\n",
            "        \"BLEU\": {\n",
            "            \"score\": 18.167978404821184,\n",
            "            \"p_value\": 0.33166833166833165,\n",
            "            \"mean\": 18.187681180235053,\n",
            "            \"ci\": 2.9864867923847838\n",
            "        },\n",
            "        \"chrF2\": {\n",
            "            \"score\": 52.12707014654113,\n",
            "            \"p_value\": 0.000999000999000999,\n",
            "            \"mean\": 52.15601163168931,\n",
            "            \"ci\": 2.543183349320042\n",
            "        }\n",
            "    }\n",
            "]\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation Results: BLEU and chrF2 with Paired Bootstrap Resampling\n",
        "\n",
        "We compared two MT systems (Marian and NLLB) on the `Vienna_Environmental.en-de.test` dataset using **BLEU** and **chrF2** metrics via `sacreBLEU` with **paired bootstrap resampling** (1000 samples). This allows us to assess not only the raw scores but also whether the differences are **statistically significant**.\n",
        "\n",
        "\n",
        "--> If p < 0.05 = significant\n",
        "\n",
        "\n",
        "\n",
        "### BLEU Scores\n",
        "\n",
        "| System       | BLEU Score | Bootstrap Mean | 95% Confidence Interval | p-value |\n",
        "|--------------|------------|----------------|--------------------------|---------|\n",
        "| Marian       | 18.77      | 19.00          | ±4.49                    | —       |\n",
        "| NLLB         | 18.17      | 18.19          | ±2.99                    | 0.332   |\n",
        "\n",
        "- Marian achieves a slightly higher BLEU score than NLLB.\n",
        "- However, the **p-value of 0.332** indicates that this difference is **not statistically significant**.\n",
        "\n",
        "### chrF2 Scores\n",
        "\n",
        "| System       | chrF2 Score | Bootstrap Mean | 95% Confidence Interval | p-value |\n",
        "|--------------|-------------|----------------|--------------------------|---------|\n",
        "| Marian       | 57.09       | 57.12          | ±2.82                    | —       |\n",
        "| NLLB         | 52.13       | 52.16          | ±2.54                    | **0.001** |\n",
        "\n",
        "- Marian outperforms NLLB by ~5 points in chrF2.\n",
        "- The **p-value of 0.001** shows this difference is **statistically significant**.\n",
        "\n",
        "### Summary\n",
        "\n",
        "- **BLEU**: No significant difference between Marian and NLLB.\n",
        "- **chrF2**: Marian performs **significantly better** than NLLB.\n",
        "\n",
        "### Interpretation\n",
        "\n",
        "BLEU is a precision-based metric on word-level n-grams, while chrF2 operates on character n-grams and tends to better capture **morphological** and **fluency-related** variations. The results suggest that although both systems perform similarly on BLEU, **Marian generates more fluent or morphologically accurate outputs**, as evidenced by the higher and statistically significant chrF2 score.\n"
      ],
      "metadata": {
        "id": "GsgHPhe4SxDU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#IMPORTANT:\n",
        "\n",
        "The code below (using one reference and one system output) simply evaluates Marian’s output against the reference using BLEU and chrF, but it does not perform any significance testing."
      ],
      "metadata": {
        "id": "rKbzJlAWSXAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sacrebleu Vienna_Environmental.en-de.test.de -l en-de -i Vienna_Environmental.en-de.test.marian.de -m bleu chrf\n",
        "#gold standard translation - sytem1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJWq6haAsBAI",
        "outputId": "59bb6f9c-f783-40e9-9531-6105a9bbf5aa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "{\n",
            " \"name\": \"BLEU\",\n",
            " \"score\": 18.8,\n",
            " \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.5.1\",\n",
            " \"verbose_score\": \"47.5/24.5/13.5/7.9 (BP = 1.000 ratio = 1.163 hyp_len = 2425 ref_len = 2086)\",\n",
            " \"nrefs\": \"1\",\n",
            " \"case\": \"mixed\",\n",
            " \"eff\": \"no\",\n",
            " \"tok\": \"13a\",\n",
            " \"smooth\": \"exp\",\n",
            " \"version\": \"2.5.1\"\n",
            "},\n",
            "{\n",
            " \"name\": \"chrF2\",\n",
            " \"score\": 57.1,\n",
            " \"signature\": \"nrefs:1|case:mixed|eff:yes|nc:6|nw:0|space:no|version:2.5.1\",\n",
            " \"nrefs\": \"1\",\n",
            " \"case\": \"mixed\",\n",
            " \"eff\": \"yes\",\n",
            " \"nc\": \"6\",\n",
            " \"nw\": \"0\",\n",
            " \"space\": \"no\",\n",
            " \"version\": \"2.5.1\"\n",
            "}\n",
            "]\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute COMET Scores\n",
        "\n",
        "Command for COMET score\n",
        "\n",
        "comet-score -s source-file  -t MT ouput -r reference-file\n",
        "\n",
        "!comet-score -s en-de.vaccine.source.en -t en-de.opuscat.original.de -r en-de.vaccine.reference.de\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yug2ryzEEnB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compute COMET  system 1\n",
        "#comet downloads a language model once per session\n",
        "!comet-score -s Vienna_Environmental.en-de.test.en -r Vienna_Environmental.en-de.test.de -t Vienna_Environmental.en-de.test.nllb.de\n",
        "\n",
        "#source sentences in en - golden standard translation - system1"
      ],
      "metadata": {
        "id": "mrapRBIJENjG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a287b11-003a-46c5-ef1c-b9aa51534c35"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-29 13:25:58.479882: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1751203558.508168    2150 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1751203558.514060    2150 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-29 13:25:58.537038: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Seed set to 1\n",
            "Fetching 5 files:   0% 0/5 [00:00<?, ?it/s]\n",
            "hparams.yaml: 100% 567/567 [00:00<00:00, 4.02MB/s]\n",
            "\n",
            "README.md: 3.40kB [00:00, 10.7MB/s]\n",
            "\n",
            ".gitattributes: 0.00B [00:00, ?B/s]\u001b[A\n",
            "\n",
            ".gitattributes: 1.48kB [00:00, 1.04MB/s]\n",
            "LICENSE: 9.69kB [00:00, 4.60MB/s]\n",
            "\n",
            "checkpoints/model.ckpt:   0% 0.00/2.32G [00:00<?, ?B/s]\u001b[A\n",
            "checkpoints/model.ckpt:   0% 39.5k/2.32G [00:01<27:05:45, 23.8kB/s]\u001b[A\n",
            "checkpoints/model.ckpt:   0% 1.77M/2.32G [00:01<27:45, 1.39MB/s]   \u001b[A\n",
            "checkpoints/model.ckpt:   0% 4.29M/2.32G [00:01<10:14, 3.77MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:   0% 6.09M/2.32G [00:01<07:00, 5.51MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:   0% 8.73M/2.32G [00:02<04:37, 8.33MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:   0% 10.8M/2.32G [00:02<03:45, 10.2MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:   1% 12.8M/2.32G [00:02<03:16, 11.7MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:   1% 15.6M/2.32G [00:02<02:32, 15.1MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:   1% 19.9M/2.32G [00:02<01:51, 20.7MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:   1% 24.0M/2.32G [00:02<01:30, 25.3MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:   1% 31.6M/2.32G [00:02<01:01, 37.3MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:   2% 42.9M/2.32G [00:03<00:55, 41.4MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:   2% 52.5M/2.32G [00:03<00:44, 51.1MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:   3% 64.4M/2.32G [00:03<00:36, 61.9MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:   3% 71.1M/2.32G [00:03<00:37, 60.3MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:   4% 84.4M/2.32G [00:03<00:31, 70.7MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:   4% 94.5M/2.32G [00:03<00:29, 75.6MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:   5% 105M/2.32G [00:03<00:32, 67.5MB/s] \u001b[A\n",
            "checkpoints/model.ckpt:   5% 113M/2.32G [00:03<00:33, 65.8MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:   5% 122M/2.32G [00:04<00:33, 65.5MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:   6% 129M/2.32G [00:04<01:02, 35.0MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:   6% 134M/2.32G [00:04<01:08, 32.1MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:   6% 149M/2.32G [00:04<00:45, 48.2MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:   7% 156M/2.32G [00:05<00:49, 44.2MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:   7% 174M/2.32G [00:05<00:44, 48.8MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:   8% 180M/2.32G [00:05<00:45, 46.8MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:   8% 186M/2.32G [00:05<00:48, 44.3MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:   9% 216M/2.32G [00:05<00:24, 85.0MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  10% 227M/2.32G [00:06<00:31, 66.5MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  10% 238M/2.32G [00:06<00:33, 62.6MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  11% 247M/2.32G [00:06<00:35, 58.7MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  11% 255M/2.32G [00:06<00:34, 60.5MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  13% 299M/2.32G [00:06<00:17, 118MB/s] \u001b[A\n",
            "checkpoints/model.ckpt:  14% 321M/2.32G [00:07<00:21, 95.2MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  15% 340M/2.32G [00:07<00:31, 63.5MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  18% 424M/2.32G [00:07<00:13, 140MB/s] \u001b[A\n",
            "checkpoints/model.ckpt:  21% 495M/2.32G [00:08<00:11, 162MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  22% 515M/2.32G [00:08<00:13, 137MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  23% 535M/2.32G [00:09<00:18, 98.3MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  24% 549M/2.32G [00:09<00:17, 103MB/s] \u001b[A\n",
            "checkpoints/model.ckpt:  28% 641M/2.32G [00:09<00:09, 180MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  29% 672M/2.32G [00:09<00:08, 192MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  31% 713M/2.32G [00:10<00:14, 108MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  32% 750M/2.32G [00:10<00:12, 127MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  34% 782M/2.32G [00:10<00:12, 125MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  37% 860M/2.32G [00:13<00:30, 48.1MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  40% 928M/2.32G [00:14<00:26, 53.2MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  43% 995M/2.32G [00:14<00:18, 72.4MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  46% 1.06G/2.32G [00:15<00:17, 73.5MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  49% 1.13G/2.32G [00:16<00:13, 89.6MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  51% 1.18G/2.32G [00:16<00:13, 83.4MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  54% 1.25G/2.32G [00:18<00:15, 68.3MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  60% 1.38G/2.32G [00:19<00:10, 92.9MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  62% 1.45G/2.32G [00:19<00:07, 111MB/s] \u001b[A\n",
            "checkpoints/model.ckpt:  65% 1.52G/2.32G [00:19<00:07, 114MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  68% 1.59G/2.32G [00:20<00:06, 110MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  71% 1.65G/2.32G [00:20<00:05, 121MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  74% 1.72G/2.32G [00:21<00:04, 123MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  77% 1.79G/2.32G [00:22<00:04, 110MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  80% 1.85G/2.32G [00:23<00:04, 103MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  83% 1.92G/2.32G [00:23<00:03, 101MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  86% 1.99G/2.32G [00:24<00:03, 111MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  88% 2.06G/2.32G [00:24<00:02, 133MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  91% 2.12G/2.32G [00:24<00:01, 156MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  94% 2.19G/2.32G [00:25<00:01, 127MB/s]\u001b[A\n",
            "checkpoints/model.ckpt:  97% 2.26G/2.32G [00:25<00:00, 138MB/s]\u001b[A\n",
            "checkpoints/model.ckpt: 100% 2.32G/2.32G [00:26<00:00, 88.6MB/s]\n",
            "Fetching 5 files: 100% 5/5 [00:26<00:00,  5.29s/it]\n",
            "Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../root/.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`\n",
            "tokenizer_config.json: 100% 25.0/25.0 [00:00<00:00, 164kB/s]\n",
            "sentencepiece.bpe.model: 100% 5.07M/5.07M [00:00<00:00, 30.5MB/s]\n",
            "tokenizer.json: 100% 9.10M/9.10M [00:00<00:00, 51.9MB/s]\n",
            "config.json: 100% 616/616 [00:00<00:00, 3.89MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n",
            "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "Predicting DataLoader 0: 100% 7/7 [15:44<00:00, 134.99s/it]\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 0\tscore: 0.5098\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 1\tscore: 0.9668\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 2\tscore: 0.8906\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 3\tscore: 0.9756\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 4\tscore: 0.9282\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 5\tscore: 0.5508\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 6\tscore: 0.8838\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 7\tscore: 0.9883\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 8\tscore: 0.8936\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 9\tscore: 0.8740\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 10\tscore: 0.8198\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 11\tscore: 0.8765\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 12\tscore: 0.8989\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 13\tscore: 0.9033\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 14\tscore: 0.7876\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 15\tscore: 0.6738\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 16\tscore: 0.9097\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 17\tscore: 0.8838\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 18\tscore: 0.8931\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 19\tscore: 0.7266\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 20\tscore: 0.8657\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 21\tscore: 0.7036\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 22\tscore: 0.9058\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 23\tscore: 0.9048\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 24\tscore: 0.7695\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 25\tscore: 0.8857\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 26\tscore: 0.8882\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 27\tscore: 0.9014\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 28\tscore: 0.7188\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 29\tscore: 0.9385\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 30\tscore: 0.7778\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 31\tscore: 0.9214\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 32\tscore: 0.7847\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 33\tscore: 0.6221\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 34\tscore: 0.7759\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 35\tscore: 0.8140\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 36\tscore: 0.8506\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 37\tscore: 0.8936\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 38\tscore: 0.8291\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 39\tscore: 0.9897\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 40\tscore: 0.9141\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 41\tscore: 0.7358\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 42\tscore: 0.8091\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 43\tscore: 0.8672\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 44\tscore: 0.8882\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 45\tscore: 0.7397\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 46\tscore: 0.8369\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 47\tscore: 0.8574\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 48\tscore: 0.8984\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 49\tscore: 0.8364\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 50\tscore: 0.7832\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 51\tscore: 0.8721\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 52\tscore: 0.7769\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 53\tscore: 0.8892\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 54\tscore: 0.6123\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 55\tscore: 0.4290\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 56\tscore: 0.8325\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 57\tscore: 0.6016\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 58\tscore: 0.7930\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 59\tscore: 0.8901\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 60\tscore: 0.6582\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 61\tscore: 0.8887\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 62\tscore: 0.8340\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 63\tscore: 0.9463\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 64\tscore: 0.6426\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 65\tscore: 0.7935\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 66\tscore: 0.7715\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 67\tscore: 0.8765\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 68\tscore: 0.8530\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 69\tscore: 0.8516\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 70\tscore: 0.9287\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 71\tscore: 0.8325\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 72\tscore: 0.8521\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 73\tscore: 0.8267\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 74\tscore: 0.8237\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 75\tscore: 0.8428\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 76\tscore: 0.8013\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 77\tscore: 0.7720\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 78\tscore: 0.7983\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 79\tscore: 0.8374\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 80\tscore: 0.8179\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 81\tscore: 0.8579\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 82\tscore: 0.8105\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 83\tscore: 0.7905\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 84\tscore: 0.7588\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 85\tscore: 0.8237\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 86\tscore: 0.8789\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 87\tscore: 0.8677\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 88\tscore: 0.6504\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 89\tscore: 0.6792\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 90\tscore: 0.8457\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 91\tscore: 0.8242\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 92\tscore: 0.8091\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 93\tscore: 0.9067\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 94\tscore: 0.8052\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 95\tscore: 0.8188\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 96\tscore: 0.8237\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 97\tscore: 0.7817\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 98\tscore: 0.9253\n",
            "Vienna_Environmental.en-de.test.nllb.de\tSegment 99\tscore: 0.9092\n",
            "Vienna_Environmental.en-de.test.nllb.de\tscore: 0.8225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pvalues for bleu: --paired-bs\n",
        "#sacrebleu ref.en-de.de -l en-de -i sys1.de sys2.de -m bleu chrf ter --paired-bs\n",
        "\n",
        "#pvalues in comet: ???\n",
        "#comet-compare -s src.de -t hyp1.en hyp2.en hyp3.en -r ref.en"
      ],
      "metadata": {
        "id": "IQgCf8X-wvsj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO\n",
        "\n",
        "1. compare bleu and chrF for orig and fine-tuned NMT (beam!!!!)\n",
        "2. compare with the p-values and CI\n",
        "3. compare with comet\n",
        "4. extra compare with QE (https://github.com/Unbabel/COMET/blob/master/MODELS.md)\n",
        "\n",
        "  Reference-free Model: Unbabel/wmt22-cometkiwi-da - This reference-free model employs a regression approach and is built on top of InfoXLM. It has been trained using direct assessments from WMT17 to WMT20, as well as direct assessments from the MLQE-PE corpus. Similar to other models, it generates scores ranging from 0 to 1. For those interested, we also offer larger versions of this model: Unbabel/wmt23-cometkiwi-da-xl with 3.5 billion parameters and Unbabel/wmt23-cometkiwi-da-xxl with 10.7 billion parameters.\n",
        "5. extra change to cometinho (https://github.com/Unbabel/COMET\n",
        "https://github.com/Unbabel/COMET/blob/master/MODELS.md)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "E-yoebHaolGz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##reference file:\n",
        "\n",
        "- Vienna_Environmental.en-de.test.de\n",
        "\n",
        "---\n",
        "\n",
        "##output files:\n",
        "\n",
        "- Vienna_Environmental.en-de.test.marian.de (translated using original model)\n",
        "- Vienna_Environmental.en-de.test.marian.vienna.beam6.de (translated using the vienna ft model)\n",
        "- Vienna_Environmental.en-de.test.marian.europat.beam6.de (translated using the europat ft model)\n"
      ],
      "metadata": {
        "id": "BITenKbLBSIS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1:\n",
        "\n"
      ],
      "metadata": {
        "id": "vszisGr8YB4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/BMT_2025S/week10_files/inference"
      ],
      "metadata": {
        "id": "pemR_e4yVSGb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd2017e2-4660-4d55-9997-fa73593fb389"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BMT_2025S/week10_files/inference\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1: Compare bleu and chrF for orig and finetuned NMT (beam6)\n",
        "\n",
        "!sacrebleu Vienna_Environmental.en-de.test.de -l en-de -i Vienna_Environmental.en-de.test.marian.de -m bleu chrf\n",
        "#gold standard translation - output of sytem0: (original model)"
      ],
      "metadata": {
        "id": "txaGfWx9_G1K",
        "outputId": "f45f80d1-0d6d-4ab4-c118-b332e50a4736",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "{\n",
            " \"name\": \"BLEU\",\n",
            " \"score\": 18.8,\n",
            " \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.5.1\",\n",
            " \"verbose_score\": \"47.5/24.5/13.5/7.9 (BP = 1.000 ratio = 1.163 hyp_len = 2425 ref_len = 2086)\",\n",
            " \"nrefs\": \"1\",\n",
            " \"case\": \"mixed\",\n",
            " \"eff\": \"no\",\n",
            " \"tok\": \"13a\",\n",
            " \"smooth\": \"exp\",\n",
            " \"version\": \"2.5.1\"\n",
            "},\n",
            "{\n",
            " \"name\": \"chrF2\",\n",
            " \"score\": 57.1,\n",
            " \"signature\": \"nrefs:1|case:mixed|eff:yes|nc:6|nw:0|space:no|version:2.5.1\",\n",
            " \"nrefs\": \"1\",\n",
            " \"case\": \"mixed\",\n",
            " \"eff\": \"yes\",\n",
            " \"nc\": \"6\",\n",
            " \"nw\": \"0\",\n",
            " \"space\": \"no\",\n",
            " \"version\": \"2.5.1\"\n",
            "}\n",
            "]\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1: Compare bleu and chrF for orig and finetuned NMT (beam6)\n",
        "\n",
        "!sacrebleu Vienna_Environmental.en-de.test.de -l en-de -i Vienna_Environmental.en-de.test.marian.vienna.beam6.de -m bleu chrf\n",
        "#gold standard translation - output of sytem1: (model ft on Vienna_Environmental.en-de.train.json)"
      ],
      "metadata": {
        "id": "xgwrbeFhVYmT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2137769b-1522-4394-dbb9-392073bda14c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "{\n",
            " \"name\": \"BLEU\",\n",
            " \"score\": 23.2,\n",
            " \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.5.1\",\n",
            " \"verbose_score\": \"53.6/29.4/17.6/10.5 (BP = 1.000 ratio = 1.039 hyp_len = 2168 ref_len = 2086)\",\n",
            " \"nrefs\": \"1\",\n",
            " \"case\": \"mixed\",\n",
            " \"eff\": \"no\",\n",
            " \"tok\": \"13a\",\n",
            " \"smooth\": \"exp\",\n",
            " \"version\": \"2.5.1\"\n",
            "},\n",
            "{\n",
            " \"name\": \"chrF2\",\n",
            " \"score\": 58.2,\n",
            " \"signature\": \"nrefs:1|case:mixed|eff:yes|nc:6|nw:0|space:no|version:2.5.1\",\n",
            " \"nrefs\": \"1\",\n",
            " \"case\": \"mixed\",\n",
            " \"eff\": \"yes\",\n",
            " \"nc\": \"6\",\n",
            " \"nw\": \"0\",\n",
            " \"space\": \"no\",\n",
            " \"version\": \"2.5.1\"\n",
            "}\n",
            "]\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1: Compare bleu and chrF for orig and finetuned NMT (beam6)\n",
        "\n",
        "!sacrebleu Vienna_Environmental.en-de.test.de -l en-de -i Vienna_Environmental.en-de.test.marian.europat.beam6.de -m bleu chrf\n",
        "#gold standard translation - output of sytem2: (model ft on EuroPat.de-en.20k.train.json)"
      ],
      "metadata": {
        "id": "cQ7ncP4q-Ojn",
        "outputId": "ef065830-9e0d-4a91-b852-c6d6d8a36b56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "{\n",
            " \"name\": \"BLEU\",\n",
            " \"score\": 15.0,\n",
            " \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.5.1\",\n",
            " \"verbose_score\": \"47.2/21.1/10.0/5.0 (BP = 1.000 ratio = 1.050 hyp_len = 2190 ref_len = 2086)\",\n",
            " \"nrefs\": \"1\",\n",
            " \"case\": \"mixed\",\n",
            " \"eff\": \"no\",\n",
            " \"tok\": \"13a\",\n",
            " \"smooth\": \"exp\",\n",
            " \"version\": \"2.5.1\"\n",
            "},\n",
            "{\n",
            " \"name\": \"chrF2\",\n",
            " \"score\": 51.8,\n",
            " \"signature\": \"nrefs:1|case:mixed|eff:yes|nc:6|nw:0|space:no|version:2.5.1\",\n",
            " \"nrefs\": \"1\",\n",
            " \"case\": \"mixed\",\n",
            " \"eff\": \"yes\",\n",
            " \"nc\": \"6\",\n",
            " \"nw\": \"0\",\n",
            " \"space\": \"no\",\n",
            " \"version\": \"2.5.1\"\n",
            "}\n",
            "]\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2:"
      ],
      "metadata": {
        "id": "A6Kf1NldAw2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Compare with the p-values and CI\n",
        "\n",
        "!sacrebleu Vienna_Environmental.en-de.test.de -l en-de -i Vienna_Environmental.en-de.test.marian.de Vienna_Environmental.en-de.test.nllb.de -m bleu chrf --paired-bs\n",
        "#gold standard translation - sytem0 - system1"
      ],
      "metadata": {
        "id": "fXhvKHEw3wC9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}